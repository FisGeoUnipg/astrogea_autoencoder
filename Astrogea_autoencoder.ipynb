{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6692f156-6068-4655-9944-e2ba8d180cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spectral import *\n",
    "import spectral.io.envi as envi\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "from scipy.signal import savgol_filter, argrelextrema\n",
    "from matplotlib.widgets import *\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.backend_bases import MouseButton\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from rasterio.control import GroundControlPoint\n",
    "from rasterio.transform import from_gcps\n",
    "from rasterio.crs import CRS\n",
    "from scipy.signal import savgol_filter , argrelextrema , find_peaks\n",
    "from kneed import KneeLocator\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib.widgets import PolygonSelector\n",
    "from itertools import permutations \n",
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d\n",
    "from numpy.random import randint , uniform , choice\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader ,SubsetRandomSampler, random_split\n",
    "from torch import optim\n",
    "import itertools\n",
    "from sklearn.metrics import silhouette_score\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac52e23-46cc-4ac5-9a62-baec34ff36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_integral_norm_data(wav , spectra):\n",
    "\n",
    "    SPECTRA = np.zeros_like(spectra)\n",
    "\n",
    "    for i in range(len(spectra[:,0])):\n",
    "        SPECTRA[i] = spectra[i]/np.trapz(spectra[i] , wav)\n",
    "        \n",
    "    return SPECTRA , wav\n",
    "\n",
    "def column_wise_norm(spectra):\n",
    "    spectra_norm = np.zeros_like(spectra)\n",
    "    for i in range(len(spectra[0])):\n",
    "        spectra_norm[:,i] = (spectra[:,i]-np.mean(spectra[:,i]))/np.std(spectra[:,i])\n",
    "        \n",
    "    return spectra_norm\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def compute_removal_single(w , spectra , interp_type = 'linear'):\n",
    "    points = np.c_[w,spectra]\n",
    "    return continuum_removal(points , interp_type = interp_type)\n",
    "\n",
    "def dimension_reduction( img , w1 , w2 , wavelength , cr = False ):\n",
    "\n",
    "    X = img.shape[0]\n",
    "    Y = img.shape[1]\n",
    "    \n",
    "    a = find_nearest(wavelength , w1)\n",
    "    b = find_nearest(wavelength , w2)\n",
    "    w = wavelength[a:b]\n",
    "    lenw = len(w)\n",
    "    \n",
    "    A = np.count_nonzero(img[:,:,0] == 65535.)\n",
    "    B = np.count_nonzero(img[:,:,0] != 65535.)\n",
    "    \n",
    "    spectra = np.zeros( (B , lenw) )\n",
    "    indexes = np.zeros( (B , 2) )\n",
    "    \n",
    "    frame_indexes = np.zeros( (A , 2) )\n",
    " \n",
    "    img = img[:,:,a:b]\n",
    "    \n",
    "    k , i , j = 0 , 0 , 0\n",
    "    while k < B and i < X and j < Y:\n",
    "        \n",
    "        if img[i,j,0] != 65535. and img[i,j,:].all() != np.zeros(lenw).all():\n",
    "            if cr == False:\n",
    "                spectra[k,:] = img[i,j,:]\n",
    "            else:\n",
    "                spectra[k,:] = compute_removal_single(w , img[i,j,:])\n",
    "            indexes[k,0] = i\n",
    "            indexes[k,1] = j   \n",
    "            k += 1\n",
    "        if img[i,j,:].all() == np.zeros(lenw).all():\n",
    "            print(i,j)\n",
    "        i += 1\n",
    "        if i == X:\n",
    "            j += 1\n",
    "            i = 0\n",
    "            if j == Y:\n",
    "                i = X\n",
    "                j = Y\n",
    "                k = B\n",
    "                  \n",
    "    return spectra , indexes , w\n",
    "\n",
    "def dimension_reduction_spectral_parameters( img , norm = None , zeros = None ):\n",
    "\n",
    "    X = img.shape[0]\n",
    "    Y = img.shape[1]\n",
    "    lenw = img.shape[2]\n",
    "    print(X,Y,lenw)\n",
    "    B = np.count_nonzero(img[:,:,0] != 65535.)\n",
    "    print(B)\n",
    "    \n",
    "    spectra = np.zeros( (B , lenw) )\n",
    "    indexes = np.zeros( (B , 2) )\n",
    "    \n",
    "    k , i , j = 0 , 0 , 0\n",
    "    while k < B and i < X and j < Y:\n",
    "        \n",
    "        if img[i,j,0] != 65535.:\n",
    "            spectra[k,:] = img[i,j,:]#[0][0]\n",
    "            \n",
    "            if zeros != None:\n",
    "                for l in range(len(spectra[k,:])):\n",
    "                    if spectra[k,l] < 0:\n",
    "                        spectra[k,l] = 0\n",
    "            \n",
    "            indexes[k,0] = i\n",
    "            indexes[k,1] = j   \n",
    "            k += 1\n",
    "        i += 1\n",
    "        if i == X:\n",
    "            j += 1\n",
    "            i = 0\n",
    "            if j == Y:\n",
    "                i = X\n",
    "                j = Y\n",
    "                k = B\n",
    "\n",
    "    if norm == 'none':\n",
    "        spectra = np.nan_to_num(spectra)\n",
    "        return spectra, indexes\n",
    "        \n",
    "    elif len(norm) > 0:\n",
    "        for p in range(len(norm)):\n",
    "    \n",
    "            if p != 0:\n",
    "                spectra = SPECTRA\n",
    "            SPECTRA = np.zeros_like(spectra)\n",
    "            \n",
    "            if norm[p] == 'row':\n",
    "                for i in range(len(spectra[:,0])):\n",
    "                    SPECTRA[i] = spectra[i]/np.sum(abs(spectra[i]))\n",
    "    \n",
    "            elif norm[p] == 'column':\n",
    "                for i in range(len(spectra[0])):\n",
    "                    if zeros != None:\n",
    "                        SPECTRA[:,i] = (spectra[:,i]-np.mean(spectra[:,i]))/np.std(spectra[:,i])\n",
    "                    else:\n",
    "                        m , s = np.mean(spectra[ np.argwhere(spectra[:,i] != 0) , i ]) , np.std(spectra[ np.argwhere(spectra[:,i] != 0) , i ])\n",
    "                        SPECTRA[:,i] = (spectra[:,i]-m)/s\n",
    "    \n",
    "            elif norm[p] == 'minmax':\n",
    "                for i in range(len(spectra[0])):\n",
    "                    if zeros != None:\n",
    "                        SPECTRA[:,i] = (spectra[:,i]-np.min(spectra[:,i]))/(np.max(spectra[:,i]) - np.min(spectra[:,i]))\n",
    "    \n",
    "            elif norm[p] == 'L1':\n",
    "                for i in range(len(spectra[0])):\n",
    "                    if zeros != None:\n",
    "                        SPECTRA[:,i] = spectra[:,i]/np.linalg.norm(spectra[:,i])\n",
    "                        \n",
    "            SPECTRA = np.nan_to_num(SPECTRA)\n",
    "\n",
    "        return SPECTRA , indexes\n",
    "\n",
    "    else:\n",
    "        print('Normalization must be either row, column, rowcolumn or none!')\n",
    "        return\n",
    "\n",
    "def continuum_removal(points , interp_type = 'linear'):#points, interp_type = 'linear'):\n",
    "    interp_types = ['linear','nearest','nearest-up','zero','slinear','quadratic','cubic','previous','next']\n",
    "    \n",
    "    if interp_type not in interp_types:\n",
    "        print('Type of interpolation must be one of:' + interp_types + '.')\n",
    "        return\n",
    "    \n",
    "    x, y = points.T\n",
    "    augmented = np.concatenate([points, [(x[0], np.min(y)-1), (x[-1], np.min(y)-1)]], axis=0)\n",
    "    hull = ConvexHull(augmented , incremental = True)\n",
    "    continuum_points = points[np.sort([v for v in hull.vertices if v < len(points)])]\n",
    "    continuum_indexs = np.array(range(0,len(continuum_points) , 1) , dtype = int)\n",
    "    continuum_function = interp1d(*continuum_points.T)\n",
    "    n = continuum_function(x)\n",
    "    \n",
    "    yprime = y / n\n",
    "\n",
    "    return yprime\n",
    "\n",
    "def compute_removal(w , spectra , interp_type = 'linear'):\n",
    "    SPECTRA = np.zeros(spectra.shape)\n",
    "    for i in range(spectra.shape[0]):\n",
    "        points = np.c_[w,spectra[i]]\n",
    "        SPECTRA[i] = continuum_removal(points , interp_type = interp_type)#points)\n",
    "    return SPECTRA\n",
    "\n",
    "def compute_removal_single(w , spectra , interp_type = 'linear'):\n",
    "    points = np.c_[w,spectra]\n",
    "    return continuum_removal(points , interp_type = interp_type)\n",
    "\n",
    "def auto_stretch_rgb(img_sr, product_names, n_bins=1000, plot=True):\n",
    "    local_only_products = { 'R530' , 'R440' , 'R600' , 'R770' , 'R1080' , 'R1506' , 'R2529' , 'R3920' , 'SH600_2' , 'IRA' , 'ISLOPE1' , 'IRR2' }\n",
    "\n",
    "    H, W, num_bands = img_sr.shape\n",
    "    stretched_cube = np.zeros((H, W, num_bands), dtype=np.float32)\n",
    "\n",
    "    for band_idx in range(num_bands):\n",
    "        band = img_sr[:, :, band_idx]\n",
    "        name = product_names[band_idx]\n",
    "        valid = np.isfinite(band) & (band != 65535)\n",
    "        vals = band[valid]\n",
    "\n",
    "        if vals.size == 0:\n",
    "            continue\n",
    "\n",
    "        if name in local_only_products:\n",
    "            vmin, vmax = np.percentile(vals, [0.1, 99.9])\n",
    "        else:\n",
    "            hist, bins = np.histogram(vals, bins=n_bins)\n",
    "            mode = (bins[np.argmax(hist)] + bins[np.argmax(hist)+1]) / 2\n",
    "            vmin = 0 if mode < 0 else mode\n",
    "            vmax = np.percentile(vals, 99.9)\n",
    "\n",
    "        stretched = np.zeros_like(band, dtype=np.float32)\n",
    "        stretched[valid] = np.clip((band[valid] - vmin) / (vmax - vmin), 0, 1)\n",
    "        stretched_cube[:, :, band_idx] = stretched[:,:,0]\n",
    "\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "            ax[0].hist(vals, bins=n_bins, color='gray', log=True)\n",
    "            ax[0].axvline(vmin, color='blue', linestyle='--', label='vmin')\n",
    "            ax[0].axvline(vmax, color='red', linestyle='--', label='vmax')\n",
    "            ax[0].set_title(f\"{name} Histogram\")\n",
    "            ax[0].legend()\n",
    "            ax[0].set_xlim(np.percentile(vals, 0), np.percentile(vals, 100))\n",
    "\n",
    "            ax[1].imshow(stretched, cmap='gray', vmin=0, vmax=1)\n",
    "            ax[1].set_title(f\"{name} Stretched\")\n",
    "            ax[1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return stretched_cube\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def auto_stretch_rgb(img_sr, product_names, n_bins=1000, plot=True, linearize=False, norm=None, zeros=False):\n",
    "    local_only_products = {\n",
    "        'R530', 'R440', 'R600', 'R770', 'R1080', 'R1506',\n",
    "        'R2529', 'R3920', 'SH600_2', 'IRA', 'ISLOPE1', 'IRR2'\n",
    "    }\n",
    "\n",
    "    H, W, num_bands = img_sr.shape\n",
    "    stretched_cube = np.zeros((H, W, num_bands), dtype=np.float32)\n",
    "\n",
    "    for band_idx in range(num_bands):\n",
    "        band = img_sr[:, :, band_idx]\n",
    "        name = product_names[band_idx]\n",
    "        valid = np.isfinite(band) & (band != 65535)\n",
    "        vals = band[valid]\n",
    "\n",
    "        if vals.size == 0:\n",
    "            continue\n",
    "\n",
    "        if name in local_only_products:\n",
    "            vmin, vmax = np.percentile(vals, [0.1, 99.9])\n",
    "        else:\n",
    "            hist, bins = np.histogram(vals, bins=n_bins)\n",
    "            mode = (bins[np.argmax(hist)] + bins[np.argmax(hist)+1]) / 2\n",
    "            vmin = 0 if mode < 0 else mode\n",
    "            vmax = np.percentile(vals, 99.9)\n",
    "\n",
    "        stretched = np.zeros_like(band, dtype=np.float32)\n",
    "        stretched[valid] = np.clip((band[valid] - vmin) / (vmax - vmin), 0, 1)\n",
    "        stretched_cube[:, :, band_idx] = stretched#[:,:,0]\n",
    "\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "            ax[0].hist(vals, bins=n_bins, color='gray', log=True)\n",
    "            ax[0].axvline(vmin, color='blue', linestyle='--', label='vmin')\n",
    "            ax[0].axvline(vmax, color='red', linestyle='--', label='vmax')\n",
    "            ax[0].set_title(f\"{name} Histogram\")\n",
    "            ax[0].legend()\n",
    "            ax[0].set_xlim(np.percentile(vals, 0.5), np.percentile(vals, 99.9))\n",
    "\n",
    "            ax[1].imshow(stretched, cmap='gray', vmin=0, vmax=1)\n",
    "            ax[1].set_title(f\"{name} Stretched\")\n",
    "            ax[1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    if not linearize:\n",
    "        return stretched_cube\n",
    "\n",
    "    # LINEARIZATION\n",
    "    valid_mask = img_sr[:, :, 0] != 65535\n",
    "    indexes = np.argwhere(valid_mask)\n",
    "    spectra = stretched_cube[valid_mask]  # shape: (N_valid, num_bands)\n",
    "\n",
    "    if zeros:\n",
    "        spectra[spectra < 0] = 0\n",
    "\n",
    "    if norm is None or norm == 'none':\n",
    "        return spectra, indexes\n",
    "\n",
    "    # Apply normalization chain\n",
    "    SPECTRA = spectra.copy()\n",
    "\n",
    "    for n in norm:\n",
    "        if n == 'row':\n",
    "            row_sums = np.sum(np.abs(SPECTRA), axis=1, keepdims=True)\n",
    "            row_sums[row_sums == 0] = 1\n",
    "            SPECTRA = SPECTRA / row_sums\n",
    "\n",
    "        elif n == 'column':\n",
    "            means = np.mean(SPECTRA, axis=0)\n",
    "            stds = np.std(SPECTRA, axis=0)\n",
    "            stds[stds == 0] = 1\n",
    "            SPECTRA = (SPECTRA - means) / stds\n",
    "\n",
    "        elif n == 'minmax':\n",
    "            mins = np.min(SPECTRA, axis=0)\n",
    "            maxs = np.max(SPECTRA, axis=0)\n",
    "            denom = maxs - mins\n",
    "            denom[denom == 0] = 1\n",
    "            SPECTRA = (SPECTRA - mins) / denom\n",
    "\n",
    "        elif n == 'L1':\n",
    "            norms = np.linalg.norm(SPECTRA, ord=1, axis=0)\n",
    "            norms[norms == 0] = 1\n",
    "            SPECTRA = SPECTRA / norms\n",
    "\n",
    "        else:\n",
    "            print(f\"Unknown norm: {n}\")\n",
    "\n",
    "    SPECTRA = np.nan_to_num(SPECTRA)\n",
    "\n",
    "    return SPECTRA, indexes\n",
    "\n",
    "def open_raw(path_img_IF , path_hdr_IF , path_img_SR , path_hdr_SR):\n",
    "    \n",
    "    img = envi.open(path_hdr_IF , path_img_IF)\n",
    "\n",
    "    img_sr = envi.open(path_hdr_SR , path_img_SR)\n",
    "\n",
    "    wavelength = np.array(img.metadata['wavelength']).astype(float)\n",
    "\n",
    "    sr_names = img_sr.metadata['band names']\n",
    "\n",
    "    return img , img_sr , wavelength , sr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e582fcef-64b9-4ba2-9b10-50c9c13942aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop/FRT00003e12/frt00003e12_07_if167j_mtr3.img\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to locate file \"Desktop/FRT00003e12/frt00003e12_07_if167j_mtr3.hdr\". If the file exists, use its full path or place its directory in the SPECTRAL_DATA environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m head_sr_mtrdr \u001b[38;5;241m=\u001b[39m path3e12 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrt000\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_07_sr167\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj_mtr3.hdr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(path_if_mtrdr)\n\u001b[1;32m---> 13\u001b[0m img , img_sr , wavelength , sr_names \u001b[38;5;241m=\u001b[39m \u001b[43mopen_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_if_mtrdr\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_if_mtrdr\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_sr_mtrdr\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_sr_mtrdr\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Provide your image data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m Nbands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(wavelength)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(sr_names)\n",
      "Cell \u001b[1;32mIn[7], line 318\u001b[0m, in \u001b[0;36mopen_raw\u001b[1;34m(path_img_IF, path_hdr_IF, path_img_SR, path_hdr_SR)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_raw\u001b[39m(path_img_IF , path_hdr_IF , path_img_SR , path_hdr_SR):\n\u001b[1;32m--> 318\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43menvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_hdr_IF\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_img_IF\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     img_sr \u001b[38;5;241m=\u001b[39m envi\u001b[38;5;241m.\u001b[39mopen(path_hdr_SR , path_img_SR)\n\u001b[0;32m    322\u001b[0m     wavelength \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavelength\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\spectral\\io\\envi.py:289\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(file, image)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(file, image\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03m    Opens an image or spectral library with an associated ENVI HDR header file.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m    Capitalized versions of the file extensions are also searched.\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     header_path \u001b[38;5;241m=\u001b[39m \u001b[43mfind_file_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     h \u001b[38;5;241m=\u001b[39m read_envi_header(header_path)\n\u001b[0;32m    291\u001b[0m     check_compatibility(h)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\spectral\\io\\spyfile.py:120\u001b[0m, in \u001b[0;36mfind_file_path\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pathname:\n\u001b[0;32m    117\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to locate file \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. If the file exists, \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse its full path or place its directory in the \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    119\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPECTRAL_DATA environment variable.\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;241m%\u001b[39m filename\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pathname\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unable to locate file \"Desktop/FRT00003e12/frt00003e12_07_if167j_mtr3.hdr\". If the file exists, use its full path or place its directory in the SPECTRAL_DATA environment variable."
     ]
    }
   ],
   "source": [
    "path3e12 = \"Desktop/FRT00003e12/\" # insert here your own path\n",
    "name = '03e12'\n",
    "\n",
    "# Example usage:\n",
    "path_if_mtrdr = path3e12 + \"frt000\" + name + \"_07_if167\" + \"j_mtr3.img\"\n",
    "head_if_mtrdr = path3e12 + \"frt000\" + name + \"_07_if167\" + \"j_mtr3.hdr\"\n",
    "\n",
    "path_sr_mtrdr = path3e12 + \"frt000\" + name + \"_07_sr167\" + \"j_mtr3.img\"\n",
    "head_sr_mtrdr = path3e12 + \"frt000\" + name + \"_07_sr167\" + \"j_mtr3.hdr\"\n",
    "\n",
    "print(path_if_mtrdr)\n",
    "\n",
    "img , img_sr , wavelength , sr_names = open_raw(path_if_mtrdr , head_if_mtrdr , path_sr_mtrdr , head_sr_mtrdr)  # Provide your image data\n",
    "\n",
    "Nbands = len(wavelength)\n",
    "print(sr_names)\n",
    "\n",
    "img , img_sr = np.array(img[:,:,:]) , np.array(img_sr[:,:,:])\n",
    "\n",
    "# deleting pure reflectance parameters\n",
    "\n",
    "sr_names_2 = np.delete(np.array(sr_names) ,\n",
    "                       [[0],[1],[8],[10],[11],[14],[52],[53],[54],[55],[56],[57],[58],[59]])\n",
    "print(sr_names_2)\n",
    "\n",
    "img_sr_2 = np.delete(img_sr[:,:,:] , [[0],[1],[8],[10],[11],[14],[52],[53],[54],[55],[56],[57],[58],[59]] , axis = 2)\n",
    "\n",
    "print(img_sr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1520eb65-0bbf-447c-be2b-2cc582cd8b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Done\n",
      "(394890, 277)\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b , SEED = 311996):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.RandomState(seed=SEED).permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "# general normalization\n",
    "#spectra , indexes = dimension_reduction_spectral_parameters( img_sr , norm = ['L1'] , zeros = True )# , 500 , 2500 , wavelength)\n",
    "# auto stretch\n",
    "#spectra , indexes = auto_stretch_rgb(img_sr_2, sr_names_2, n_bins=1000, plot=False, linearize=True, norm=['column'], zeros=True)\n",
    "\n",
    "# mean 0 and std 1 norm\n",
    "spectra = column_wise_norm(spectra)\n",
    "\n",
    "print( np.count_nonzero(spectra.all() == np.zeros(img.shape[2]).all()) )\n",
    "print( 'Done' )\n",
    "\n",
    "print(spectra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8835eafd-7f58-417b-a55e-fe0df5fe30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GumbelSoftmax(nn.Module):\n",
    "    def __init__(self, temperature=1.0, hard=False):\n",
    "        super(GumbelSoftmax, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.hard = hard\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.gumbel_softmax(x, tau=self.temperature, hard=self.hard)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, encoded_space_dim, in_channels, n_layers_encoder, n_layers_decoder, out1, out2, act, drops , last):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.encoded_space_dim = encoded_space_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.n_layers_encoder = n_layers_encoder\n",
    "        self.n_layers_decoder = n_layers_decoder\n",
    "        self.out1 = out1\n",
    "        self.out2 = out2\n",
    "        self.drops = drops\n",
    "    \n",
    "        self.model = []\n",
    "        if self.n_layers_encoder == 1:\n",
    "            self.model.append(nn.Linear(self.in_channels, self.out1[0]))\n",
    "            self.model.append(nn.BatchNorm1d(self.out1[0]))\n",
    "            self.model.append(act)\n",
    "            self.model.append(nn.Dropout(self.drops[0]))\n",
    "            self.model.append(nn.Linear(self.out1[0], encoded_space_dim))\n",
    "            \n",
    "        elif self.n_layers_encoder == 0:\n",
    "            self.model.append(nn.Linear(self.in_channels, encoded_space_dim))\n",
    "            self.model.append(act)\n",
    "        else:\n",
    "            for i in range(self.n_layers_encoder):\n",
    "                if i == self.n_layers_encoder-1:\n",
    "                    self.model.append(nn.Linear(self.out1[i], self.encoded_space_dim))\n",
    "                elif i == 0:\n",
    "                    self.model.append(nn.Linear(self.in_channels, self.out1[i]))\n",
    "                    self.model.append(nn.BatchNorm1d(self.out1[i]))\n",
    "                    self.model.append(nn.Dropout(self.drops[i]))\n",
    "                    self.model.append(act)\n",
    "                    self.model.append(nn.Linear(self.out1[i], self.out1[i+1]))\n",
    "                    self.model.append(nn.Dropout(self.drops[i+1]))\n",
    "                    self.model.append(act)\n",
    "                else:   \n",
    "                    self.model.append(nn.Linear(self.out1[i], self.out1[i+1]))\n",
    "                    self.model.append(nn.BatchNorm1d(self.out1[i+1]))\n",
    "                    self.model.append(nn.Dropout(self.drops[i+1]))\n",
    "                    self.model.append(act)\n",
    "                    \n",
    "        # Add GumbelSoftmax to nn.Sequential\n",
    "        self.encoder = nn.Sequential(*self.model, GumbelSoftmax(temperature=1.0, hard=True))\n",
    "        \n",
    "        self.model2 = []\n",
    "        \n",
    "        if self.n_layers_decoder == 0:\n",
    "            self.model2.append(nn.Linear(self.encoded_space_dim, self.in_channels))\n",
    "        elif self.n_layers_decoder == 1:\n",
    "            self.model2.append(nn.Linear(self.encoded_space_dim, self.out2[0]))\n",
    "            self.model2.append(act)\n",
    "            self.model2.append(nn.Linear(self.out2[0], self.in_channels))\n",
    "        else:\n",
    "            self.model2.append(nn.Linear(self.encoded_space_dim, self.out2[0]))\n",
    "            self.model2.append(act)\n",
    "            for i in range(self.n_layers_decoder-1):\n",
    "                self.model2.append(nn.Linear(self.out2[i], self.out2[i+1]))\n",
    "                self.model2.append(act)\n",
    "            self.model2.append(nn.Linear(self.out2[self.n_layers_decoder-1], self.in_channels))\n",
    "            self.model2.append(nn.Tanh())\n",
    "        self.decoder = nn.Sequential(*self.model2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def weight_init(model, init_method):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if init_method == 'kaiming_normal':\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "            elif init_method == 'kaiming_uniform':\n",
    "                nn.init.kaiming_uniform_(module.weight)\n",
    "            elif init_method == 'xavier_normal':\n",
    "                nn.init.xavier_normal_(module.weight)\n",
    "            elif init_method == 'xavier_uniform':\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "            elif init_method == 'uniform':\n",
    "                nn.init.uniform_(module.weight)\n",
    "            elif init_method == 'normal':\n",
    "                nn.init.normal_(module.weight)\n",
    "            elif init_method == 'ones':\n",
    "                nn.init.ones_(module.weight)\n",
    "            #elif init_method == 'zeros':\n",
    "            #    nn.init.zeros_(module.weight)\n",
    "            elif init_method == 'eye':\n",
    "                nn.init.eye_(module.weight)\n",
    "            elif init_method == 'orthogonal':\n",
    "                nn.init.orthogonal_(module.weight)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid initialization method!\")\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "\n",
    "INITS = ['kaiming_normal' , 'kaiming_uniform' , 'xavier_normal' , 'xavier_uniform' , 'uniform' , 'normal' , 'ones' ,# 'zeros' ,\n",
    "         'eye' , 'orthogonal']\n",
    "def RandomSearch_autoencoder(dataset , in_channels, criterion , encoded_space_dim ,\n",
    "                             n_encmax , n_decmax , MINenc , MAXenc, MINdec, MAXdec,\n",
    "                             activations , initializations = INITS,\n",
    "                             fix_enc = False , fix_dec = False ,\n",
    "                             try_epochs = 10 , N_try = 10 , Seed = torch.seed() ,\n",
    "                             printer = 'off' , bs = 100 , num_pieces = 5 , val_split = 0.2):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(device)\n",
    "    \n",
    "    # Initialize names and arrays of hyperparameters\n",
    "    hyperparanames = ['LR','outC','outL','n_conv_layers','n_lin_layers','encoded_space_dim','weight_initialization']\n",
    "    \n",
    "    rate , W , L1 = [] , [] , []\n",
    "    train_l = []\n",
    "    val_l = []\n",
    "    Lenc = np.zeros((N_try , n_encmax))\n",
    "    Ldec = np.zeros((N_try , n_decmax))\n",
    "    enc = []\n",
    "    ACT = []\n",
    "    DROPS = []\n",
    "    inits = []\n",
    "\n",
    "    total_len = len(dataset)\n",
    "    val_len = int(total_len * val_split)\n",
    "    train_len = total_len - val_len\n",
    "    \n",
    "    train_set, val_set = random_split(dataset, [train_len, val_len], generator=torch.Generator().manual_seed(Seed))\n",
    "    TL = DataLoader(train_set, batch_size=bs, shuffle=True, pin_memory=True)\n",
    "    VL = DataLoader(val_set, batch_size=bs, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    for i in range(N_try):\n",
    "        \n",
    "        losses = []\n",
    "        validations = []\n",
    "        \n",
    "        ENCSPDIM = choice(encoded_space_dim)\n",
    "        \n",
    "        print('Try' , str(i))\n",
    "        \n",
    "        if fix_dec == False:\n",
    "            n_dec = randint( 0 , n_decmax+1 )\n",
    "        else:\n",
    "            n_dec = n_decmax\n",
    "            \n",
    "        if fix_enc == False:\n",
    "            n_enc = randint( 0 , n_encmax+1 )\n",
    "        else:\n",
    "            n_enc = n_encmax\n",
    "\n",
    "        LR  = choice(np.array([1,5]))*choice(np.array([0.00001 , 0.0001 , 0.001 , 0.01 , 0.1]))\n",
    "        \n",
    "        outLenc = np.sort(choice(np.arange(MINenc*5 , MAXenc*5+5 , 5 , dtype = int)  , n_enc))[::-1]\n",
    "        outLdec = np.sort(choice(np.arange(MINdec*5 , MAXdec*5+5 , 5 , dtype = int)  , n_dec))\n",
    "        \n",
    "        dropouts = choice([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] , n_enc+1)\n",
    "\n",
    "        l1_reg = choice([1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10])\n",
    "\n",
    "        initials = choice(np.array(initializations))\n",
    "        inits.append(initials)\n",
    "        \n",
    "        act = choice(activations)\n",
    "        ACT.append(act)\n",
    "        DROPS.append(dropouts)\n",
    "\n",
    "        # Generating the model with the randomly generated hyperparameters\n",
    "        \n",
    "        model = Net(ENCSPDIM , in_channels , n_enc , n_dec , outLenc , outLdec , act , dropouts , True).to(device)\n",
    "        #print(model)\n",
    "        weight = choice([1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10])\n",
    "\n",
    "        weight_init(model, init_method = initials)\n",
    "        \n",
    "        optimizer = choice([optim.Adam(model.parameters() , lr = LR , weight_decay = weight)])\n",
    "\n",
    "        for epoch in range(try_epochs):\n",
    "            model.train()\n",
    "            LOSS = 0\n",
    "            for x in TL:\n",
    "                x = x.float().to(device)\n",
    "                y = model(x)\n",
    "                loss = criterion(y, x)\n",
    "                l1_lambda = l1_reg\n",
    "                l1 = sum(param.abs().sum() for param in model.parameters())\n",
    "                loss += l1_lambda * l1\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                LOSS += loss.item()\n",
    "            LOSS /= len(TL)\n",
    "            losses.append(LOSS)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        VAL_LOSS = 0\n",
    "        with torch.no_grad():\n",
    "            for x in VL:\n",
    "                x = x.float().to(device)\n",
    "                y = model(x)\n",
    "                val_loss = criterion(y, x)\n",
    "                VAL_LOSS += val_loss.item()\n",
    "        VAL_LOSS /= len(VL)\n",
    "        val_l.append(VAL_LOSS)\n",
    "\n",
    "        # Updating the arrays with the randomly generated values\n",
    "        rate.append(LR)\n",
    "        W.append(weight)\n",
    "        enc.append(ENCSPDIM)\n",
    "        L1.append(l1_reg)\n",
    "\n",
    "        for j in range(n_enc):\n",
    "            Lenc[i,j] = outLenc[j]\n",
    "        for j in range(n_dec):\n",
    "            Ldec[i,j] = outLdec[j]\n",
    "        \n",
    "        # Updating the arrays of the losses + accuracy with the last losses\n",
    "        train_l.append(np.array(losses)[-1])#.mean())\n",
    "        print('Final loss value = ' , train_l[i])\n",
    "\n",
    "    J = np.argmin(np.asarray(val_l))#train_l))\n",
    "    \n",
    "    # Printing out the best values relatively to the chosen method\n",
    "    print( '\\x1b[4;34;43m'+'Best results is '+'\\x1b[0m' , J , '\\x1b[4;34;43m'+'. With values: '+'\\x1b[0m' ,\n",
    "           \"\\n\" ,  hyperparanames , \"\\n\" , rate[J] , Lenc[J] , Ldec[J] , W[J] , enc[J] , ACT[J] , DROPS[J] , inits[J] , L1[J] )#, seeds[J] )\n",
    "    \n",
    "    return rate[J] , Lenc[J] , Ldec[J] , W[J] , enc[J] , ACT[J] , DROPS[J] , inits[J] , L1[J]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6a12d0ce-7858-4459-a101-eb55290e2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 781, 277)\n"
     ]
    }
   ],
   "source": [
    "shape = spectra2.shape#len(wavelength[a:b])#60\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec558335-9fcd-4262-88de-60b5006e598a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "238118\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "DIM = 3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ds , test_ds = train_test_split(spectra , test_size=0.1, random_state=311996)\n",
    "\n",
    "train_ds , valid_ds = train_test_split(train_ds , test_size=0.33, random_state=200960)\n",
    "\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2ae3c-def9-4022-bf0d-7a9989f9c201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Try 0\n",
      "Final loss value =  5.63027206226252e-05\n",
      "Try 1\n",
      "Final loss value =  0.020442016422748566\n",
      "Try 2\n"
     ]
    }
   ],
   "source": [
    "a = find_nearest(wavelength , 1000)\n",
    "b = find_nearest(wavelength , 2600)\n",
    "\n",
    "shape = 277  # 46\n",
    "torch.manual_seed(533733874069400)\n",
    "params = RandomSearch_autoencoder( spectra , shape , nn.HuberLoss() ,\n",
    "                                   encoded_space_dim = np.arange(5,11).tolist() ,\n",
    "                                   n_encmax = 1 , n_decmax = 2 ,\n",
    "                                   MINenc = 2 , MAXenc = 15 ,\n",
    "                                   MINdec = 2 , MAXdec = 15 ,\n",
    "                                   activations = [ nn.Mish() , nn.GELU() , nn.SiLU() , nn.ReLU() ] ,\n",
    "                                   fix_enc = False , fix_dec = True , \n",
    "                                   try_epochs = 20 , N_try = 60, Seed = torch.seed() , \n",
    "                                   printer = 'off' ,\n",
    "                                   bs = spectra.shape[0] ,\n",
    "                                   num_pieces = spectra.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e51094ee-7a83-4f3b-94c4-d0b36b5532f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=277, out_features=6, bias=True)\n",
      "    (1): Mish(inplace=True)\n",
      "    (2): GumbelSoftmax()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=35, bias=True)\n",
      "    (1): Mish(inplace=True)\n",
      "    (2): Linear(in_features=35, out_features=50, bias=True)\n",
      "    (3): Mish(inplace=True)\n",
      "    (4): Linear(in_features=50, out_features=55, bias=True)\n",
      "    (5): Mish(inplace=True)\n",
      "    (6): Linear(in_features=55, out_features=60, bias=True)\n",
      "    (7): Mish(inplace=True)\n",
      "    (8): Linear(in_features=60, out_features=60, bias=True)\n",
      "    (9): Mish(inplace=True)\n",
      "    (10): Linear(in_features=60, out_features=277, bias=True)\n",
      "    (11): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "wav = len(wavelength[a:b])#60\n",
    "\n",
    "DIM = params[4]#DIM\n",
    "torch.manual_seed(533733874069400)#params[6])#205653840223300)\n",
    "model = Net( encoded_space_dim = DIM , \n",
    "            in_channels = shape ,\n",
    "             n_layers_encoder = np.count_nonzero(params[1]) ,\n",
    "             n_layers_decoder = np.count_nonzero(params[2]) ,\n",
    "             out1 = params[1].astype(int) , out2 = params[2].astype(int) ,\n",
    "             act = nn.Mish(x),#params[5] ,\n",
    "             drops = params[6] , last = True ).to(device)\n",
    "\n",
    "weight_init(model, init_method = params[-2])\n",
    "\n",
    "print(model)\n",
    " \n",
    "loader = torch.utils.data.DataLoader( dataset = spectra ,\n",
    "                                      batch_size = spectra.shape[0],\n",
    "                                      shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "62dcbc1e-8266-4696-a03d-50d181fdde32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 2/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 3/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 4/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 5/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 6/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 7/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 8/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 9/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 10/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 11/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 12/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 13/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n",
      "Epoch 14/500 -> Train Loss: 0.0000 | Validation Loss: 0.0000 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_losses, validation_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHuberLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[96], line 99\u001b[0m, in \u001b[0;36mtrain_cnn\u001b[1;34m(model, criterion, train_ds, validation_ds, num_epochs, patience, weight_decay, bs, device, LR, printer)\u001b[0m\n\u001b[0;32m     97\u001b[0m y_true \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     98\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m validation_loader:\n\u001b[0;32m    100\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    101\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(x)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\clean_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:285\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, validation_losses = train_cnn( model, nn.HuberLoss(), \n",
    "                                             train_ds, valid_ds, \n",
    "                                             500 , 25,\n",
    "                                             params[-1], len(train_ds), \n",
    "                                             DEVICE, params[0], printer = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad0fea-5eaf-45ff-a783-4221508eaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_losses , 'b' , linewidth = 1 , label = 'train loss')\n",
    "plt.plot(validation_losses , 'r' , linewidth = 1 , label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Extract Low-dimensional Representations\n",
    "encoded_data = model.encoder(torch.tensor(spectra).float().to(device)).detach().cpu().numpy()#model.encoder(torch.tensor(spectra).float()).detach().numpy()\n",
    "\n",
    "def plot_n_encoded(spectra , model , DIM , plot = True):\n",
    "    # Extract Low-dimensional Representations\n",
    "    encoded_data = model.encoder(torch.tensor(spectra).float()).detach().numpy()\n",
    "    \n",
    "    if plot:\n",
    "        fig , ax = plt.subplots(DIM,DIM)\n",
    "        for i in range(DIM):\n",
    "            for j in range(DIM):\n",
    "                if i != j and i < j:\n",
    "                    ax[i,j].plot(encoded_data[:,i] , encoded_data[:,j] , 'k.')\n",
    "                    ax[i,j].set_xlabel('Encoded Dimension '+str(i+1) , fontsize = 5)\n",
    "                    ax[i,j].set_ylabel('Encoded Dimension '+str(j+1) , fontsize = 5)\n",
    "                else:\n",
    "                    ax[i,j].axis('off')\n",
    "        plt.show()\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a451a90-f0b7-4e70-b62e-91f63027af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 781, 60)\n",
      "['R770' 'RBR' 'BD530_2' 'SH600_2' 'SH770' 'BD640_2' 'BD860_2' 'BD920_2'\n",
      " 'RPEAK1' 'BDI1000VIS' 'R440' 'IRR1' 'BDI1000IR' 'OLINDEX3' 'R1330'\n",
      " 'BD1300' 'LCPINDEX2' 'HCPINDEX2' 'VAR' 'ISLOPE1' 'BD1400' 'BD1435'\n",
      " 'BD1500_2' 'ICER1_2' 'BD1750_2' 'BD1900_2' 'BD1900R2' 'BDI2000'\n",
      " 'BD2100_2' 'BD2165' 'BD2190' 'MIN2200' 'BD2210_2' 'D2200' 'BD2230'\n",
      " 'BD2250' 'MIN2250' 'BD2265' 'BD2290' 'D2300' 'BD2355' 'SINDEX2' 'ICER2_2'\n",
      " 'MIN2295_2480' 'MIN2345_2537' 'BD2500_2' 'BD3000' 'BD3100' 'BD3200'\n",
      " 'BD3400_2' 'CINDEX2' 'BD2600' 'IRR2' 'IRR3' 'R530' 'R600' 'R1080' 'R1506'\n",
      " 'R2529' 'R3920']\n",
      "(744, 781, 3)\n"
     ]
    }
   ],
   "source": [
    "print(rgbs.shape)\n",
    "print(sr_names)\n",
    "i = np.where((np.array(sr_names) == 'R2529'))[0][0]\n",
    "j = np.where((np.array(sr_names) == 'R1506'))[0][0]\n",
    "k = np.where((np.array(sr_names) == 'R1080'))[0][0]\n",
    "print(rgbs[:,:,[i,j,k]].shape)\n",
    "\n",
    "sr_names = np.array(sr_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8fd0d8d-c60b-408e-8754-4b41bd9784e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 (394890, 10)\n",
      "58 57 56\n"
     ]
    }
   ],
   "source": [
    "RGB_autoencoder = np.zeros( (img_sr.shape[0] , img_sr.shape[1] , DIM) )\n",
    "\n",
    "print(DIM , encoded_data.shape)\n",
    "\n",
    "for j in range(DIM):\n",
    "    E = encoded_data[:,j]\n",
    "    for i in range(len(indexes[:,0])):\n",
    "        x , y = int(indexes[i,0]) , int(indexes[i,1])\n",
    "        RGB_autoencoder[x,y,j] = E[i]\n",
    "\n",
    "false = pyfresco.SpectraExtract(img, Nbands, wavelength, 400, 2600)\n",
    "fal = false.upload_map('FAL' , folder = 'FRT00003e12/')\n",
    "\n",
    "I = np.where((np.array(sr_names) == 'R2529'))[0][0]\n",
    "J = np.where((np.array(sr_names) == 'R1506'))[0][0]\n",
    "K = np.where((np.array(sr_names) == 'R1080'))[0][0]\n",
    "print(I , J , K)\n",
    "fig , ax = plt.subplots(1,DIM+1)\n",
    "ax[0].imshow( rgbs[:,:,[I,J,K]])\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('False color')\n",
    "for j in range(DIM):\n",
    "    ax[j+1].imshow( RGB_autoencoder[:,:,j] , cmap = 'viridis' )\n",
    "    ax[j+1].axis('off')\n",
    "    ax[j+1].set_title('Neuron '+str(j+1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cmap = matplotlib.colormaps.get_cmap('viridis')\n",
    "\n",
    "bounds = np.linspace(0,DIM,DIM+1 , dtype = int)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "pixelsN = np.zeros((img.shape[0] , img.shape[1]))\n",
    "for i in range(DIM):\n",
    "    mappa = RGB_autoencoder[:,:,i]\n",
    "    ind = np.argwhere(RGB_autoencoder[:,:,i] != 0)\n",
    "    pixelsN[ind[:,0] , ind[:,1]] = i\n",
    "\n",
    "for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "        if img[i,j,0] == 65535:\n",
    "            pixelsN[i,j] = -1\n",
    "\n",
    "fig , ax = plt.subplots(1,2)\n",
    "ax[0].imshow( rgbs[ : , : , [I,J,K] ] )\n",
    "im = ax[1].imshow(pixelsN , cmap = cmap)\n",
    "plt.colorbar(im , ticks=bounds , norm = norm , boundaries=bounds)\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7239a9ff-5a94-4e59-8d57-b218057a3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "n_plots = DIM + 1  # 1 for false color + DIM neurons\n",
    "n_cols = math.ceil(math.sqrt(n_plots))\n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "axes = axes.flatten()  # Flatten to use as a 1D list\n",
    "\n",
    "# Plot false color image\n",
    "axes[0].imshow(rgbs[:, :, [I, J, K]])\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('False color')\n",
    "\n",
    "# Plot each neuron's activation map\n",
    "for j in range(DIM):\n",
    "    axes[j+1].imshow(RGB_autoencoder[:, :, j], cmap='viridis')\n",
    "    axes[j+1].axis('off')\n",
    "    axes[j+1].set_title('Neuron ' + str(j+1))\n",
    "\n",
    "# Hide unused axes if any\n",
    "for i in range(n_plots, len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04e5edb7-e95a-4100-bbcf-86f4b45c4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import StrMethodFormatter\n",
    "w1 , w2 = 400,2600\n",
    "A = find_nearest(wavelength , w1)\n",
    "B = find_nearest(wavelength , w2)\n",
    "wav = wavelength[A:B]\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "k , l = 0 , 0\n",
    "fig , ax = plt.subplots(2,DIM , figsize = [5,5] , sharey='row')\n",
    "for i in range(DIM):\n",
    "    \n",
    "    i_n = np.argwhere(RGB_autoencoder[:,:,i] == 1)\n",
    "\n",
    "    \n",
    "    S = np.array(img[:,:,:])[i_n[:,0],i_n[:,1],A:B]\n",
    "    \n",
    "    if 65535 in S:\n",
    "        S = np.delete(S , np.argwhere(S == np.ones(B-A , dtype = float)*65535.0) , axis = 0)\n",
    "    \n",
    "    s , se = np.mean(S , axis = 0) , np.std(S , axis = 0)\n",
    "    \n",
    "    means.append(s)\n",
    "    stds.append(se)\n",
    "    \n",
    "for i in range(DIM):\n",
    "    ax[0,i].plot(wav , means[i] , 'k')\n",
    "    ax[0,i].plot(wav , means[i]+stds[i] ,'k--')\n",
    "    ax[0,i].plot(wav , means[i]-stds[i] ,'k--')\n",
    "    ax[0,i].fill_between(wav , means[i]-stds[i] , means[i]+stds[i] , color = 'black' , alpha = 0.5)\n",
    "    ax[0,i].set_title('Neuron '+str(i+1))\n",
    "    \n",
    "    ax[1,i].imshow(RGB_autoencoder[:,:,i])\n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "    ax[0,i].set_xlabel('Wavelength [nm]')\n",
    "        \n",
    "ax[0,0].set_ylabel('Reflectance')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
